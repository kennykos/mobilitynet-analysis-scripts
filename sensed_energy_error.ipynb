{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23f8062",
   "metadata": {},
   "source": [
    "# Sensed Energy Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09039587",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ab1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading and validating data\n",
    "import emeval.input.spec_details as eisd\n",
    "import emeval.input.phone_view as eipv\n",
    "import emeval.input.eval_view as eiev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e12e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers\n",
    "import emeval.viz.phone_view as ezpv\n",
    "import emeval.viz.eval_view as ezev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pipelined data\n",
    "import emeval.analysed.phone_view as eapv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb02ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3508f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely as shp\n",
    "import shapely.geometry as shpgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f700b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emeval.viz.geojson as ezgj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emeval.metrics.dist_calculations as emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cda128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytics results\n",
    "import emeval.metrics.segmentation as ems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242bec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for statistics\n",
    "import scipy as sp\n",
    "import scipy.stats as spst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier debugging while working on modules\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98681dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/gkosmach/Documents/every_trip_counts/e-mission-server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.analysis.intake.cleaning.location_smoothing as eaicl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41223e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d512591",
   "metadata": {},
   "source": [
    "### Load in Phone Views for Server or Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(eipv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f53b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import emission.core.get_database as edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9c7bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# edb.get_timeseries_error_db().find().distinct(\"metadata.key\")\n",
    "# edb.get_timeseries_db().find().distinct(\"metadata.key\")\n",
    "# edb.get_timeseries_db().count_documents({\"metadata.key\": \"manual/evaluation_transition\"})\n",
    "# list(edb.get_timeseries_error_db().find({\"metadata.key\": \"manual/evaluation_transition\"}).limit(3))\n",
    "# edb.get_timeseries_error_db().find({\"metadata.key\": \"manual/evaluation_transition\"}).distinct(\"data.transition\")\n",
    "# # list(edb.get_timeseries_db().find({\"metadata.key\": \"manual/evaluation_transition\"}).limit(3))\n",
    "# # edb.get_usercache_db().find({\"metadata.key\": \"manual/evaluation_transition\"}).distinct(\"data.transition\")\n",
    "# # list(edb.get_timeseries_error_db().find({\"metadata.key\": \"manual/evaluation_transition\", \"data.transition\": \"START_EVALUATION_PERIOD\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99796534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AUTHOR_EMAIL = \"shankari@eecs.berkeley.edu\"\n",
    "# # If using ServerSpecDetails, data can alternatively be retrieved as such:\n",
    "# DATASTORE_LOC = \"http://localhost:8080\"\n",
    "# sd = eisd.ServerSpecDetails(DATASTORE_LOC, AUTHOR_EMAIL, \"train_bus_ebike_mtv_ucb\")\n",
    "# pv = eipv.PhoneView(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142aecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_sd_and_pv_from_server(trips  = [\"unimodal_trip_car_bike_mtv_la\", \"car_scooter_brex_san_jose\", \"train_bus_ebike_mtv_ucb\"], \n",
    "                                 AUTHOR_EMAIL  = \"shankari@eecs.berkeley.edu\", \n",
    "                                 DATASTORE_LOC = \"http://localhost:8080\", \n",
    "                                 pkl_file_name = None):\n",
    "    sd_l = []\n",
    "    pv_l = []\n",
    "    for trip in trips:\n",
    "        sd = eisd.ServerSpecDetails(DATASTORE_LOC, AUTHOR_EMAIL, trip)\n",
    "        pv = eipv.PhoneView(sd)\n",
    "        sd_l.append(sd)\n",
    "        pv_l.append(pv)\n",
    "    if pkl_file_name:\n",
    "        import pickle\n",
    "        with open(pkl_file_name, 'wb') as outp:\n",
    "            for pv in pv_l:\n",
    "                pickle.dump(pv, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    return sd_l, pv_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_pv_from_pkl(pkl_file_name, \n",
    "                       trips = [\"unimodal_trip_car_bike_mtv_la\", \"car_scooter_brex_san_jose\", \"train_bus_ebike_mtv_ucb\"]):\n",
    "    import pickle\n",
    "    pv_l = []\n",
    "    with open('pv.pkl', 'rb') as inp:\n",
    "        for trip in trips:\n",
    "            pv_l.append(pickle.load(inp))\n",
    "    return pv_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91330c18",
   "metadata": {},
   "source": [
    "#### Phone View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a4d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pv_la, pv_sj, pv_ucb) = import_pv_from_pkl('pv.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33f54a",
   "metadata": {},
   "source": [
    "#### Clean View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_la = eapv.create_analysed_view(pv_la, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")\n",
    "av_sj = eapv.create_analysed_view(pv_sj, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")\n",
    "av_ucb = eapv.create_analysed_view(pv_ucb, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/cleaned_section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610699b",
   "metadata": {},
   "source": [
    "#### GIS view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_la = eapv.create_analysed_view(pv_la, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/inferred_section\")\n",
    "gv_sj = eapv.create_analysed_view(pv_sj, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/inferred_section\")\n",
    "gv_ucb = eapv.create_analysed_view(pv_ucb, \"http://localhost:8080\", \"analysis/recreated_location\", \"analysis/cleaned_trip\", \"analysis/inferred_section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485db253",
   "metadata": {},
   "source": [
    "# Temporally Aligned Histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3925105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emeval.metrics.reference_trajectory as emr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852156e8",
   "metadata": {},
   "source": [
    "## Spacio Temporal Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f90d7b",
   "metadata": {},
   "source": [
    "#### Get histories for phone views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histories(pv, os, role):\n",
    "    assert os in ['android', 'ios'], 'UNKNOWN OS'\n",
    "    assert role in ['accuracy_control', 'HAHFDC', 'HAMFDC', 'MAHFDC', 'power_control'], \"UNKNOWN ROLE\"\n",
    "    trips = []\n",
    "    for phone_os, phone_map in pv.map().items():\n",
    "        if os != phone_os:\n",
    "            continue\n",
    "        for phone_label, phone_detail_map in phone_map.items():\n",
    "            if \"control\" in phone_detail_map[\"role\"]:\n",
    "                continue\n",
    "            for r_idx, r in enumerate(phone_detail_map[\"evaluation_ranges\"]):\n",
    "                if r['eval_role_base'] != role:\n",
    "                    continue\n",
    "                tr_ss  = []\n",
    "                tr_gts = []\n",
    "                for i, tr in enumerate(r[\"evaluation_trip_ranges\"]):\n",
    "                    for ss in tr[\"sensed_section_ranges\"]:\n",
    "                        ## s = d / t -> t = d / s\n",
    "                        ## append the sensed section time and mode data\n",
    "                        tr_ss.append(ss)\n",
    "                    for section in tr[\"evaluation_section_ranges\"]:\n",
    "                        ### begin: get gt time and mode data\n",
    "                        ## get the ground truth section data\n",
    "                        gt_leg = pv.spec_details.get_ground_truth_for_leg(\n",
    "                                                        tr[\"trip_id_base\"], \n",
    "                                                        section[\"trip_id_base\"], \n",
    "                                                        tr['start_ts'], \n",
    "                                                        tr['end_ts']\n",
    "                                                    )\n",
    "\n",
    "                        if gt_leg[\"type\"] == \"WAITING\": \n",
    "                            continue\n",
    "                            \n",
    "                        gts = {\n",
    "                            'start_ts': section['start_ts'], \n",
    "                            'end_ts': section['end_ts'], \n",
    "                            'mode': gt_leg['mode'], \n",
    "                            }\n",
    "                        tr_gts.append(gts)\n",
    "                        ### end: get gt time and mode data\n",
    "                # now, we build a timeline for each trip\n",
    "                trip = tr.copy()\n",
    "                trip['inf']  = tr_ss\n",
    "                trip['gt'] = tr_gts\n",
    "                trip['tz'] = pv.spec_details.eval_tz\n",
    "                trips.append(trip)\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e6962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_histories(gv_la, 'ios', 'HAHFDC');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d3067",
   "metadata": {},
   "source": [
    "#### Pad the start and end of a timeline, fill in the transitios with 'ghost' mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ee1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_fill_history(trip):\n",
    "    h_inf = trip['inf']\n",
    "    gt_timeline = trip['gt']\n",
    "    h_inf_padded = []\n",
    "    h_gt_padded = []\n",
    "    ####### FILL IN SENSED TIMELINE #######\n",
    "    ### fill in start ###\n",
    "    if len(h_inf) == 0:\n",
    "        if len(gt_timeline) == 0:\n",
    "            return h_inf, gt_timeline\n",
    "        else:\n",
    "            h_inf.append(\n",
    "                {\n",
    "                    'mode' : 'NO_SENSED_START',\n",
    "                    'start_ts' : gt_timeline[0]['start_ts'],\n",
    "                    'end_ts' : gt_timeline[-1]['end_ts']\n",
    "                }\n",
    "            )\n",
    "    if len(gt_timeline) == 0:\n",
    "        gt_timeline.append(\n",
    "            {\n",
    "                'mode' : 'NO_GT_START',\n",
    "                'start_ts' : h_inf[0]['start_ts'],\n",
    "                'end_ts' : h_inf[-1]['end_ts']\n",
    "            }\n",
    "        )\n",
    "    if 'data' in h_inf[0]:\n",
    "        start_misalignment = h_inf[0]['data']['start_ts'] - gt_timeline[0]['start_ts']\n",
    "        end_misalignment = h_inf[-1]['data']['end_ts'] - gt_timeline[-1]['end_ts']\n",
    "    else:\n",
    "        start_misalignment = h_inf[0]['start_ts'] - gt_timeline[0]['start_ts']\n",
    "        end_misalignment = h_inf[-1]['end_ts'] - gt_timeline[-1]['end_ts']\n",
    "\n",
    "    if start_misalignment > 0:\n",
    "        if 'data' in h_inf[0].keys():\n",
    "            h_inf[0] = h_inf[0]['data']\n",
    "        \n",
    "        h_inf_padded.append(\n",
    "            {\n",
    "                'mode' : 'NO_SENSED_START',\n",
    "                'start_ts' : h_inf[0]['start_ts'] - start_misalignment,\n",
    "                'end_ts' : h_inf[0]['start_ts']\n",
    "            }\n",
    "        )\n",
    "    ### fill in meat ###\n",
    "    for ss in h_inf:\n",
    "        if 'data' in ss.keys():\n",
    "            ss = ss['data']\n",
    "        if 'sensed_mode' in ss.keys():\n",
    "            ss['mode'] = ss['sensed_mode']\n",
    "        if len(h_inf_padded) > 0:\n",
    "            ## check to see if there is a gap ##\n",
    "            if ss['start_ts'] - h_inf_padded[-1]['end_ts'] > 0:\n",
    "                ## fill in the blank\n",
    "                h_inf_padded.append(\n",
    "                    {\n",
    "                        'mode' : 'NO_SENSED_MIDDLE', \n",
    "                        'start_ts' : h_inf_padded[-1]['end_ts'],\n",
    "                        'end_ts' : ss['start_ts']\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "        ## the timeline is continuous, and we can fill our section ##\n",
    "        h_inf_padded.append(ss)\n",
    "    ### fill in end ###\n",
    "    if end_misalignment < 0:\n",
    "        ss = h_inf[-1]\n",
    "        if 'data' in ss.keys():\n",
    "            ss = ss['data']\n",
    "        h_inf_padded.append(\n",
    "            {\n",
    "                'mode' : 'NO_SENSED_END',\n",
    "                'start_ts' : ss['end_ts'],\n",
    "                'end_ts' : ss['end_ts'] - end_misalignment\n",
    "            }\n",
    "        )\n",
    "    ####### FILL IN GT TIMELINE #######\n",
    "    ### fill in start ###\n",
    "    if start_misalignment < 0:\n",
    "        h_gt_padded.append(\n",
    "            {\n",
    "                'mode' : 'NO_GT_START',\n",
    "                'start_ts' : gt_timeline[0]['start_ts'] + start_misalignment,\n",
    "                'end_ts' : gt_timeline[0]['start_ts']\n",
    "            }\n",
    "        )\n",
    "    ### fill in meat ###\n",
    "    for gts in gt_timeline:\n",
    "        if len(h_gt_padded) > 0:\n",
    "            ## fill in the blank ##\n",
    "            if gts['start_ts'] - h_gt_padded[-1]['end_ts'] > 0:\n",
    "                h_gt_padded.append(\n",
    "                    {\n",
    "                        'mode' : 'NO_GT_MIDDLE',\n",
    "                        'start_ts' : h_gt_padded[-1]['end_ts'],\n",
    "                        'end_ts' : gts['start_ts']\n",
    "                    }\n",
    "                )\n",
    "        h_gt_padded.append(gts)\n",
    "    ### fill in end ###\n",
    "    if end_misalignment > 0:\n",
    "        h_gt_padded.append(\n",
    "            {\n",
    "                'mode' : 'NO_GT_END',\n",
    "                'start_ts' : h_gt_padded[-1]['end_ts'],\n",
    "                'end_ts' : h_gt_padded[-1]['end_ts'] + end_misalignment\n",
    "            }\n",
    "        )\n",
    "    return h_inf_padded, h_gt_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e20fa",
   "metadata": {},
   "source": [
    "## Align the histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_histories(os, role, pv, test=False, test_trip=None):\n",
    "    if not test:\n",
    "        if type(pv) is not list: pv = [pv]\n",
    "        trips = []\n",
    "        for v in pv:\n",
    "            trips.extend(get_histories(v, os, role))\n",
    "    else:\n",
    "        trips = test_trip if type(test_trip) is list else [test_trip]\n",
    "    for trip in trips:\n",
    "        ### Get resampled\n",
    "        trip_geo_df = emd.to_geo_df(trip['location_df'])\n",
    "        trip['resampled_df'] = emr.get_int_aligned_trajectory(trip_geo_df, tz=trip['tz'])\n",
    "        trip['resampled_df'] = eaicl.add_dist_heading_speed(trip['resampled_df'])\n",
    "        ### Pad and Fill in histories\n",
    "        H_inf, H_gt = pad_and_fill_history(trip)\n",
    "        ### Begin Temporal Alignment\n",
    "        H_alligned= []\n",
    "        j = 0\n",
    "        for i in range(len(H_inf)):\n",
    "            while j < len(H_gt):\n",
    "                if H_gt[j]['end_ts'] < H_inf[i]['start_ts']:\n",
    "                    ## get next gt entry\n",
    "                    j = j + 1\n",
    "                elif H_inf[i]['end_ts'] > H_gt[j]['start_ts'] and H_inf[i]['start_ts'] < H_gt[j]['end_ts']:\n",
    "                    h_a = {}\n",
    "                    start_ts = max(H_gt[j]['start_ts'], H_inf[i]['start_ts'])\n",
    "                    end_ts   = min(H_gt[j]['end_ts'], H_inf[i]['end_ts'])\n",
    "                    inf_mode = H_inf[i]['mode']\n",
    "                    gt_mode  = H_gt[j]['mode']\n",
    "                    distance = 0\n",
    "                    interval_df = trip['resampled_df'].query(f\"ts >= {start_ts} and ts <= {end_ts}\")\n",
    "                    if interval_df.count().max() > 0:\n",
    "                        distance = interval_df['distance'].sum()\n",
    "                    ### create alignment interval\n",
    "                    h_a = {\n",
    "                        'start_ts' : start_ts,\n",
    "                        'end_ts'   : end_ts,\n",
    "                        'inf_mode' : inf_mode,\n",
    "                        'gt_mode'  : gt_mode,\n",
    "                        'duration' : end_ts - start_ts,\n",
    "                        'distance' : distance\n",
    "                    }\n",
    "                    H_alligned.append(h_a)\n",
    "                    ## get next gt entry\n",
    "                    j = j + 1\n",
    "                else: \n",
    "                    ## check if next inf anf prev gt entry have overlap\n",
    "                    if i + 1 < len(H_inf) and j > 0 and H_inf[i+1]['start_ts'] < H_gt[j-1]['end_ts']:\n",
    "                        ## get prev gt entry\n",
    "                        j = j-1\n",
    "                    break\n",
    "    return H_alligned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9d2d9",
   "metadata": {},
   "source": [
    "### Build Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrices(os, role, pv):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f3be3",
   "metadata": {},
   "source": [
    "### Get the sensed/ground-truth trip lengths, making sure that trips do not bleed in to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ad4d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_ss_and_gts_dists(pv_l, os, role):\n",
    "    if type(pv_l) is not list:\n",
    "        pv_l = [pv_l]\n",
    "    trip_dists = []\n",
    "    for pv in pv_l:\n",
    "        for phone_os, phone_map in pv.map().items():\n",
    "            if os != phone_os: continue\n",
    "            for phone_label, phone_detail_map in phone_map.items():\n",
    "                for r in phone_detail_map[\"evaluation_ranges\"]:\n",
    "                    if role not in r['eval_role']: continue\n",
    "                    if 'control' in r['eval_role']: continue\n",
    "                    run_ss_dist, run_gt_dist = 0,0\n",
    "                    for i, tr in enumerate(r[\"evaluation_trip_ranges\"]):\n",
    "                        sensed_dist, gt_dist = 0,0\n",
    "                        for ss in tr['sensed_section_ranges']:\n",
    "                            if 'data' in ss.keys():\n",
    "                                if i > 0: assert ss['data']['start_ts'] > r[\"evaluation_trip_ranges\"][i-1]['end_ts']\n",
    "                                if i > 0: assert ss['data']['start_ts'] > trip_dists[-1]['gt_end_ts']\n",
    "                                sensed_dist += ss['data']['distance']\n",
    "                            else:\n",
    "                                sensed_dist = eaicl.add_dist_heading( tr['location_df'] ).distance.sum()\n",
    "                                break\n",
    "                        run_ss_dist += sensed_dist\n",
    "                        for sr in tr['evaluation_section_ranges']:\n",
    "                            ##### Ground Truth Distance ######\n",
    "                            gt_leg = pv.spec_details.get_ground_truth_for_leg(\n",
    "                                tr[\"trip_id_base\"], \n",
    "                                sr[\"trip_id_base\"], \n",
    "                                tr['start_ts'], \n",
    "                                tr['end_ts']\n",
    "                            )\n",
    "                            gt_shapes = gpd.GeoSeries(eisd.SpecDetails.get_shapes_for_leg(gt_leg))\n",
    "                            return gt_shapes\n",
    "                            if len(gt_shapes) <= 1:\n",
    "                                continue\n",
    "                            ## GET THE TOTAL GT DISTANCE OF A SECTION\n",
    "                            gt_linestring = gt_shapes['route']\n",
    "                            gt_geo_df = emd.linestring_to_geo_df(gt_linestring)\n",
    "                            gt_loc_df = emd.to_loc_df(gt_geo_df)\n",
    "                            gt_loc_with_dist_df =  eaicl.add_dist_heading( gt_loc_df )\n",
    "                            gt_dist += gt_loc_with_dist_df['distance'].sum()\n",
    "                        run_gt_dist += gt_dist\n",
    "                        trip_dists.append(\n",
    "                            {\n",
    "                                'sensed_distance' : sensed_dist,\n",
    "                                'ground_truth_distance' : gt_dist,\n",
    "                                'gt_end_ts' : tr['evaluation_section_ranges'][-1]['end_ts']\n",
    "                            }\n",
    "                        )\n",
    "    return trip_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52591217",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(eaicl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62843070",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ss_and_gts_dists(pv_la, 'ios', 'HAHFDC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aaf5d6",
   "metadata": {},
   "source": [
    "# CANBIKECO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aad1c3",
   "metadata": {},
   "source": [
    "## Perturb Trip Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats as spst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error_df, relative_error_df = get_approx_err('ios', 'HAHFDC', [av_la, av_sj, av_ucb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = spst.gaussian_kde(relative_error_df.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0df976",
   "metadata": {},
   "source": [
    "#### We use the resample function to sample from our kernel for the $n$ needed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33444dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kernel(100).T)\n",
    "x = np.linspace(-2,2,300)\n",
    "y=kernel(x)\n",
    "plt.plot(x,kernel(x))\n",
    "plt.plot(x, spst.gaussian_kde(kernel.resample(50))(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dec5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.get_database as edb\n",
    "import emission.storage.decorations.trip_queries as esdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(edb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b37675",
   "metadata": {},
   "source": [
    "## Get Phone Views from Spec Detials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80224f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phone_views(spec_details):\n",
    "    if type(spec_details) is not list:\n",
    "        speci_details = [spec_details]\n",
    "    phone_view_list = []\n",
    "    analyzed_view_list = []\n",
    "    for sd in speci_details:\n",
    "        pv = eipv.PhoneView(sd)\n",
    "        phone_view_list.append(pv)\n",
    "        av = eapv.create_analysed_view(\n",
    "            pv, \n",
    "            sd.DATASTORE_LOC, \n",
    "            \"analysis/recreated_location\", \n",
    "            \"analysis/cleaned_trip\", \n",
    "            \"analysis/cleaned_section\")\n",
    "        analyzed_view_list.append(av)\n",
    "    return phone_view_list, analyzed_view_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb33de",
   "metadata": {},
   "source": [
    "## Set Up Error_Rates_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d466877",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_view_list = [av_la, av_sj, av_ucb]\n",
    "Error_Dict = {\n",
    "        \"relative_distance_errors\" :\n",
    "        {\n",
    "            \"android:HAMFDC\" : np.array(get_approx_err('android', 'HAMFDC', analyzed_view_list)[-1]).tolist(),\n",
    "            \"ios:HAHFDC\"     : np.array(get_approx_err('ios', 'HAHFDC', analyzed_view_list)[-1]).tolist()\n",
    "        }\n",
    "    }\n",
    "Error_Rates_db.delete_one({}) ## todo: need to just delete relative distance errors\n",
    "Error_Rates_db.insert_one(Error_Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee482ad",
   "metadata": {},
   "source": [
    "## approximation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approx_err(os, role, pv_l):\n",
    "    trip_dist = get_ss_and_gts_dists(pv_l, os, role)\n",
    "    relative_error = []\n",
    "    absolute_error = []\n",
    "    for i in range(len(trip_dist)):\n",
    "        abs_err = (trip_dist[i]['sensed_distance'] - trip_dist[i]['ground_truth_distance'])\n",
    "        rel_err = abs_err / trip_dist[i]['ground_truth_distance']\n",
    "        relative_error.append(rel_err)\n",
    "        absolute_error.append(abs_err)\n",
    "    return absolute_error, relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702f40d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_Error_Rates_db(spec_details):\n",
    "    phone_view_list, analyzed_view_list = get_phone_views(spec_details)\n",
    "    Error_Dict = {\n",
    "            \"relative_distance_errors\" :\n",
    "            {\n",
    "                \"android:HAMFDC\" : np.array(get_approx_err('android', 'HAMFDC', analyzed_view_list)[-1]).tolist(),\n",
    "                \"ios:HAHFDC\"     : np.array(get_approx_err('ios', 'HAHFDC', analyzed_view_list)[-1]).tolist()\n",
    "            }\n",
    "        }\n",
    "    Error_Rates_db = edb.get_Error_Rates_db()\n",
    "    try:\n",
    "        Error_Rates_db.insert_one(Error_Dict)\n",
    "    except:\n",
    "        Error_Rates_db.delete_one({}) ## todo: need to just delete relative distance errors\n",
    "        Error_Rates_db.insert_one(Error_Dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b22fe",
   "metadata": {},
   "source": [
    "## Get Phone OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.wrapper.user as ecwu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.apply(lambda trip : edb.get_profile_db().find_one({'user_id': trip['user_id']}),axis=1).apply(pd.Series)['curr_platform']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253bae39",
   "metadata": {},
   "source": [
    "## Add dominant mode and artificial GT to dataframes\n",
    "These opperations are expensive, and can be done in parrellel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884030b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_mode(s):\n",
    "    sections = s[0] #need to unpack into list of sections\n",
    "    i = np.argmax(\n",
    "        [\n",
    "            section['data']['duration'] for section in sections\n",
    "        ]\n",
    "    ) # get the dominant mode\n",
    "    return sections[i]['data']['sensed_mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d567f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dominant_mode_to_df(trips):\n",
    "    sections = trips.apply(lambda t : esdt.get_sections_for_trip(\"analysis/inferred_section\", t[\"user_id\"], t['data']['cleaned_trip']), axis=1)\n",
    "    dominant_mode = sections.to_frame().apply(get_dominant_mode, axis=1)\n",
    "    trips['data'] = pd.concat([trips['data'].apply(pd.Series), dominant_mode], axis=1).rename({0 : 'dominant_mode'}, axis=1).to_dict('records')\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e40af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_os_to_df(trips):\n",
    "    try:\n",
    "        trips['data'].apply(pd.Series).drop('OS', axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    os = trips.apply(lambda trip : edb.get_profile_db().find_one({'user_id': trip['user_id']}),axis=1).apply(pd.Series)['curr_platform']\n",
    "    trips['data'] = pd.concat([trips['data'].apply(pd.Series), os], axis=1).rename({0 : 'OS'}, axis=1).to_dict('records')\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernels():\n",
    "    Error_Rates_db = edb.get_Error_Rates_db() ## need to make sure this is filled out\n",
    "    error_rates_df = pd.DataFrame(edb.get_Error_Rates_db().find({}))\n",
    "    android_errors = error_rates_df['relative_distance_errors'].apply(pd.Series)['android:HAMFDC'][0]\n",
    "    ios_errors     = error_rates_df['relative_distance_errors'].apply(pd.Series)['ios:HAHFDC'][0]\n",
    "    return spst.gaussian_kde(android_errors), spst.gaussian_kde(ios_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f5a199",
   "metadata": {},
   "source": [
    "#### Find the artificial ground truth for a dataframe\n",
    "\n",
    "$$\n",
    "r = \\frac{sensed - gt}{gt} \\iff sensed = gt(r+1) \\iff gt = \\frac{sensed}{r+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a21acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "android_kernel, ios_kernel = get_kernels()\n",
    "# try: \n",
    "#     trips['data'].apply(pd.Series)['OS']\n",
    "# except:\n",
    "#     trips = add_os_to_df(trips)\n",
    "add_dominant_mode_to_df(trips)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c037f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_artificial_gt_distance_to_df(trips):\n",
    "    android_kernel, ios_kernel = get_kernels()\n",
    "    try: \n",
    "        trips['data']['OS']\n",
    "    except:\n",
    "        add_os_to_df(trips)\n",
    "    artificial_gt = np.array(pd.DataFrame(trips)['data'].apply(pd.Series)['distance']) / (np.array(kernel.resample(len(pd.DataFrame(trips)))) + 1)\n",
    "    trips['data'] = pd.concat([trips['data'].apply(pd.Series), pd.Series(artificial_gt.flatten())], axis=1).rename({0 : 'artificial_gt_distance'}, axis=1).to_dict('records')\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea5b518",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "upper_limit = 10\n",
    "trips = [doc for doc in Stage_analysis_timeseries.find({\"metadata.key\":\"analysis/confirmed_trip\"})]\n",
    "trips = pd.DataFrame(trips[:upper_limit])\n",
    "sections = trips.apply(lambda t : esdt.get_sections_for_trip(\"analysis/inferred_section\", t[\"user_id\"], t['data']['cleaned_trip']), axis=1)\n",
    "dominant_mode = sections.to_frame().apply(get_dominant_mode, axis=1)\n",
    "trips['data'] = pd.concat([trips['data'].apply(pd.Series), dominant_mode], axis=1).rename({0 : 'dominant_mode'}, axis=1).to_dict('records')\n",
    "artificial_gt = np.array(pd.DataFrame(trips)['data'].apply(pd.Series)['distance']) / (np.array(kernel.resample(len(pd.DataFrame(trips)))) + 1)\n",
    "trips['data'] = pd.concat([trips['data'].apply(pd.Series), pd.Series(artificial_gt.flatten())], axis=1).rename({0 : 'artificial_gt_distance'}, axis=1).to_dict('records')\n",
    "trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25befda2",
   "metadata": {},
   "source": [
    "## Get the artificial GT distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_gt = np.array(pd.DataFrame(confirmed_trips)['data'].apply(pd.Series)['distance']) / (np.array(kernel.resample(len(pd.DataFrame(confirmed_trips)))) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(confirmed_trips)\n",
    "df['data'].apply(pd.Series).columns\n",
    "\n",
    "\n",
    "#.inferred_labels.to_frame()[df['data'].apply(pd.Series)#.inferred_labels.to_frame().astype(bool)].query('inferred_labels == inferred_labels')['inferred_labels'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f14bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
